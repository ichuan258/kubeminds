metricsAddr: ":8080"
probeAddr: ":8081"
enableLeaderElection: false

# LLM Configuration
# The API Key for the LLM provider. Can also be set via OPENAI_API_KEY environment variable.
apiKey: "AIzaSyAyGqqGo0InN6Im9Ymi5LUf3AvRLcpMcnQ"

# The model to use (e.g., gpt-4o, gemini-1.5-pro, deepseek-coder, etc.)
model: "gemini-3-pro"

# The Base URL for the LLM provider (default: https://api.openai.com/v1)
# Examples:
# - OpenAI: https://api.openai.com/v1
# - Gemini (via Proxy): https://generativelanguage.googleapis.com/v1beta/openai/ (requires proxy or compatible gateway)
# - LocalAI: http://localhost:8080/v1
# - DeepSeek: https://api.deepseek.com/v1
# - Moonshot (Kimi): https://api.moonshot.cn/v1
baseUrl: "https://api.openai.com/v1"
